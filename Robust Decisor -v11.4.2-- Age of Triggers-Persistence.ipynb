{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4aaee01",
   "metadata": {},
   "source": [
    "## ROBUSTA - 11.4.2 - Age of Triggers - Persistence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2509226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance\n",
    "import requests\n",
    "import matplotlib.pyplot\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from numpy import percentile, sign, amax, amin, arange, where, random, log, exp, inf, where, select, sqrt, nan, mean, abs, linspace, argmax, argmin, zeros, maximum, isfinite, sign\n",
    "import pandas\n",
    "import pandas_ta\n",
    "# Setup\n",
    "pandas.set_option('future.no_silent_downcasting', True)\n",
    "from pandas.tseries.offsets import BDay, MonthBegin\n",
    "from datetime import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import itertools\n",
    "from tqdm import tqdm  # Biblioteca para mostrar uma barra de progresso\n",
    "from icecream import ic\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5331ad-d12a-4b7b-a8b4-127dcb7d0e81",
   "metadata": {},
   "source": [
    "### História"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "660519b9-1119-46e6-acb5-cdde665e2835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# O retorno médio volta a ser um importante indicador de risco. \n",
    "# Apesar de ser difícil achar um indicador com correção positiva. Usar gatilhos para a escolha de indicadores aumenta os ganhos e diminui as perdas\n",
    "# Além disso, confirmar algum rompimento por k dias pode aumentar a chance de descobrir qual indicador é mais potente nos mercados\n",
    "\n",
    "# x.x.2 - Utiliza o 'Adj Close' do df exportado para todos os cálculos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54811892",
   "metadata": {},
   "source": [
    "### Versão "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11e70ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versão da Robusta \n",
    "\n",
    "# 1 - \n",
    "\n",
    "versao = \"11.4.2 - Age of Triggers - Persistence\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0fc719",
   "metadata": {},
   "source": [
    "### Funções Gerais e Administrativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3de2ca6b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def configurar_data(data_ajuste, ano=0, mes=0, dia=1):    \n",
    "\n",
    "    adjusted_date = data_ajuste - pandas.DateOffset(years=ano, months=mes, days=dia)\n",
    "    \n",
    "    return adjusted_date\n",
    "\n",
    "\n",
    "def ler_todos_tickers():    \n",
    "    return pandas.read_excel('lista_tickers_corrigido.xlsx')    \n",
    "\n",
    "\n",
    "def first_day_alert(date):\n",
    "    \"\"\"\n",
    "    Função retorna true se hoje for o primeiro bussiness day\n",
    "    \"\"\"\n",
    "\n",
    "    # Encontre o primeiro dia do mês atual\n",
    "    primeiro_dia_do_mes = pandas.offsets.MonthBegin().rollback(hoje)\n",
    "\n",
    "    # Vá para o próximo dia útil\n",
    "    primeiro_dia_util = primeiro_dia_do_mes + BDay(0)\n",
    "\n",
    "    # Verifique se a data atual é igual ao primeiro dia útil do mês\n",
    "    if hoje == primeiro_dia_util:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def find_latest_market_days(total_days):\n",
    "    \"\"\"\n",
    "    Lista as datas de operação do mercado.\n",
    "    Importante para o backtest conseguir calcular corretamente 5, 10, 15 e 20 dias pois as datas de negociação não seguirem um padrão perfeitamente regular.\n",
    "    \"\"\"    \n",
    "    # Baixando os dados do BOVA11\n",
    "    ticker = yfinance.download('BOVA11.SA', progress=False, period='1y')\n",
    "\n",
    "    # Obtendo as últimas 60 datas e convertendo para string\n",
    "    latest_market_days = ticker.tail(total_days).index.strftime('%Y-%m-%d').tolist()    \n",
    "    \n",
    "    return latest_market_days\n",
    "\n",
    "\n",
    "def alerta_final_do_mes():\n",
    "    '''\n",
    "    Final de mês tem oscilações técnicas de fluxo\n",
    "    '''\n",
    "\n",
    "    ultimo_dia_do_mes = hoje + pandas.tseries.offsets.MonthEnd(0)\n",
    "    dois_dias_uteis_antes = ultimo_dia_do_mes - BDay(2)\n",
    "\n",
    "    if hoje >= dois_dias_uteis_antes:\n",
    "        \n",
    "        return f'Final de Mês. Estresse na Posição'\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "def crie_variacao(stock_data, info_in, info_out): \n",
    "    '''\n",
    "    Coloca a variação na coluna de nome info_out da coluna que recebe o argumento em info_in \n",
    "    \n",
    "    '''        \n",
    "                                 \n",
    "    # adiciona coluna de variação\n",
    "    stock_data[info_out] = stock_data[info_in].pct_change()\n",
    "    \n",
    "    # retorna o dataframe\n",
    "    return stock_data\n",
    "\n",
    "\n",
    "def crie_medias_moveis(stock_data, *args): #recebe o dataframe e as médias para cálculo \n",
    "    \n",
    "    for i in args:\n",
    "        \n",
    "        # adiciona uma coluna extra no dataset com os dados da mma\n",
    "        stock_data[f'MMA{i}'] = stock_data['Adj Close'].rolling(window=i).mean()  \n",
    "        \n",
    "    return stock_data\n",
    "    \n",
    "\n",
    "def release_date_alert(df):\n",
    "\n",
    "      \n",
    "    df['Alerta'] = df['Data de Divulgação de resultados'].apply(lambda x: 'Inverter posição. Publicação de Resultado' \n",
    "                                                if 0 < (x - hoje).days < 2 else f'Robust_{versao}')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def verticalize_preços_fechamento(df):\n",
    "    \"\"\"\n",
    "    Cria colunas *_var_desloc* usando a média móvel de fechamento\n",
    "    (SMA de `ma_window` dias, default = 14) para suavizar distorções.\n",
    "\n",
    "    Para cada `d` em days_list:\n",
    "        coluna 'Xd_var_desloc' = SMA14_t+X / SMA14_t  - 1\n",
    "    \"\"\"\n",
    "\n",
    "    ma_window = 4\n",
    "    \n",
    "    # 1) SMA-14 do preço de fechamento\n",
    "    sma = df['Adj Close'].rolling(ma_window).mean()\n",
    "\n",
    "    # 2) Deslocamentos futuros baseados nessa média suavizada\n",
    "    for days in days_list:\n",
    "        col = f'{days}d_var_desloc'\n",
    "        df[col] = (sma.shift(-days) / sma) - 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19f12a1",
   "metadata": {},
   "source": [
    "### Todos os parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40d1caed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| hoje: Timestamp('2025-06-11 19:58:58.914194')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    }
   ],
   "source": [
    "# Datas\n",
    "hoje = pandas.Timestamp.now()\n",
    "ic(hoje)\n",
    "\n",
    "data_formatada = hoje.date()\n",
    "\n",
    "# A data de início do download do dataframe\n",
    "data_inicio = configurar_data(hoje, 5, 0, 0)\n",
    "\n",
    "# Dias de backtest\n",
    "total_days_backtest = 25 # um mês e um dia para evitar que faltem 20 registros a partir da última da de montagem realizada\n",
    "\n",
    "# Encontrar a data de inicio\n",
    "backtest_inicial = hoje - BDay(total_days_backtest + 1)\n",
    "\n",
    "# Últimas 60 datas de negociação do mercado\n",
    "latest_market_days = find_latest_market_days(60)\n",
    "        \n",
    "# Obtendo a data mais recente do df \n",
    "end_date = latest_market_days[-1]\n",
    "\n",
    "# BACKTEST - Dias para os quais você deseja calcular as datas futuras\n",
    "days_list = [10, 20, 30, 45, 90]\n",
    "\n",
    "# Persistance - Manutenção da flag após k dias.\n",
    "'''\n",
    "df[\"break_n\"] = (\n",
    "    (df[\"Close\"] > df[\"High\"].rolling(20).max().shift(1))  # rompeu topo de 20 d\n",
    "    .rolling(k).sum() == k                                 # fez isso k dias seguidos\n",
    ")\n",
    "'''\n",
    "global k \n",
    "k = 10\n",
    "\n",
    "# Ações\n",
    "# Lista de tickers que darão problemas\n",
    "probleminhas = []\n",
    "\n",
    "probleminhas_temp = [] # Antes de mandar para o registro definitivo, cai aqui\n",
    "\n",
    "# Setup técnico\n",
    "# Listas de MMA (Médias móveis Aritméticas)\n",
    "mma_list = [9, 26, 200]\n",
    "\n",
    "# Lista de Momentum\n",
    "# momentum_list = [30]\n",
    "\n",
    "# Volatilidade Anualizada\n",
    "mes_anualized_vol = ['30']\n",
    "\n",
    "# Lista de ATRs\n",
    "atr_windows = [5 , 14] \n",
    "\n",
    "# Tolerâncias\n",
    "# de perda  \n",
    "tolerancia_perda = 0.05\n",
    "# Introduzir um fator de desvio para determinar sinais significativos\n",
    "tolerancia_erro = 0.005\n",
    "\n",
    "# Window de atr_stops e RSI (14 dias porque é o padrão de mercado)\n",
    "stop_atr = 14\n",
    "rsi_window = stop_atr\n",
    "\n",
    "# Macro\n",
    "# Lista\n",
    "macro = ['^TNX', 'BOVA11.SA','SMAL11.SA'] \n",
    "\n",
    "# Setup\n",
    "\"\"\"\n",
    "Por que não usa só uma variável em macro e técnico? Porque o backtest fica muito grande e \n",
    "perde a função primordial, além de ficar muito pesado\n",
    "\"\"\"\n",
    "macro_mma_list = [10, 50] # Listas de mma\n",
    "macro_momentum_list = [10, 20] # Lista de Momentum\n",
    "\n",
    "\n",
    "# Strings de nomes e endereços\n",
    "diretorio_arquivo = 'C:/Users/gioch/Desktop/Python/Acompanhamento do Mercado - Jupyter/'\n",
    "# Nome que completará o arquivo\n",
    "nome_arquivo = f'{diretorio_arquivo}Robust-{versao}-{data_formatada}' \n",
    "# URLs para informações fundamentalistas\n",
    "url_release_dates = \"https://www.empiricus.com.br/artigos/investimentos/agenda-de-resultados-4t23-divulgacao-calendario-temporada-balancos-4t2023-quarto-trimestre-2023/\"\n",
    "# https://www.moneytimes.com.br/agenda-de-resultados-do-4t23-veja-datas-e-o-que-esperar-dos-balancos-das-empresas-da-b3/\n",
    "\n",
    "# Indicadores Financeiros\n",
    "url_financials = f'https://www.fundamentus.com.br/detalhes.php?papel='\n",
    "\n",
    "# DFs, Listas e Dicionários\n",
    "\n",
    "# Cria dicionários para armazenar os dados já buscado\n",
    "data_cache_macro_tickers = {}\n",
    "# Datas de publicações de resultados\n",
    "all_ticker_release_dates = None\n",
    "# Lista para armazenar os resultados temporários\n",
    "resultados_temp_backtest = []  \n",
    "\n",
    "# Instruções\n",
    "# Indicador para rodar o test comparativo de indicadores\n",
    "test_indicadores = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a370dc39",
   "metadata": {},
   "source": [
    "### Bloco Técnico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd5af4b-4973-46d9-b84d-3d5b654378a7",
   "metadata": {},
   "source": [
    "#### Cálculos indicadores   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81f0c850-a86a-49d5-b7ca-60da5c0a56ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisa_tecnicamente_cotacoes(ticker):\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" \n",
    "    \n",
    "    stock_data = yfinance.download(\n",
    "        ticker, \n",
    "        progress=False, \n",
    "        start=data_inicio,\n",
    "        auto_adjust=False,\n",
    "        multi_level_index=False)      \n",
    "\n",
    "    \n",
    "    # se o método download retornar vazio, encerrar a função\n",
    "    if stock_data.empty:\n",
    "        return False\n",
    "\n",
    "    # Verificar se o volume médio dos últimos 30 dias é menor que 10.000\n",
    "    if stock_data['Volume'].tail(30).mean().item() < 10000:\n",
    "        return False\n",
    "       \n",
    "    else:\n",
    "                       \n",
    "        # adicionar coluna de variação do ticker\n",
    "        stock_data = crie_variacao(stock_data, 'Adj Close','Return')\n",
    "        \n",
    "        # adicionar colunas de médias móveis aritméticas\n",
    "        stock_data = crie_medias_moveis(stock_data, *mma_list)\n",
    "        # stock_data = create_mma_position(stock_data, mma_list)       \n",
    "        stock_data = create_mma_direction(stock_data, mma_list)       \n",
    "                \n",
    "        # Indicadores de volatilidade\n",
    "        # stock_data = calcule_volatilidade_anualizada(stock_data, 30) # 30 porque são os dias que mais se assemelham  ao utilizado pelo mercado de derivativos \n",
    "        # stock_data = calculate_obv(stock_data)\n",
    "        # stock_data = calcule_exaustao_atr(stock_data)\n",
    "        # stock_data = calcule_vwap(stock_data)\n",
    "\n",
    "        # Confirmadores\n",
    "        # 1 - Volume\n",
    "        # Window =20, 150% acima da média\n",
    "        stock_data = alto_volume_diario(stock_data, 20, 1.5)\n",
    "        # stock_data = alto_volume_diario(stock_data, 20, 2)\n",
    "        # Movivento forte que faciita reversão   \n",
    "        # defautlt -> def up_or_down_trend(df, trend_pct=0.03, trending_days=5): ->0.03\n",
    "        # stock_data = up_or_down_trend(stock_data)\n",
    "        # 10%\n",
    "        # stock_data = up_or_down_trend(stock_data,0.1)\n",
    "        # 20%\n",
    "        # stock_data = up_or_down_trend(stock_data,0.20)\n",
    "        # 30%\n",
    "        # stock_data = up_or_down_trend(stock_data,0.30)\n",
    "\n",
    "        # Indicadores Técnicos\n",
    "        # stock_data = calculate_rsi(stock_data, 9)\n",
    "        # stock_data = calculate_rsi(stock_data, 21)\n",
    "        # stock_data = calculate_rsi(stock_data, 30)\n",
    "        \n",
    "        # Indicadores Candlestick\n",
    "        # 1 - Martelo\n",
    "        # def candlestick_martelo(df, wick_pct=2., head_pct=0.1):\n",
    "        # stock_data = candlestick_martelo(stock_data) #default NÃO RETIRE ele é usado para combinar indicadores\n",
    "        # stock_data = candlestick_martelo(stock_data, 2.5,0)\n",
    "        # 2 - Engolfo\n",
    "        # stock_data = candlestick_engolfo(stock_data)\n",
    "              \n",
    "        # Combinação de indicadores\n",
    "        #stock_data = combine_indicadores(stock_data, 'Candlestick_martelo_2,0.1_?value', 'up_or_down_trend.25_?value')\n",
    "        #stock_data = combine_indicadores(stock_data, 'Candlestick_martelo_2,0.1_?value', 'up_or_down_trend.03_?value')\n",
    "        # DESLIG stock_data = combine_indicadores(stock_data, 'Candlestick_martelo_2,0.1_?value', 'Alto_volume_1_?value')\n",
    "        # stock_data = combine_indicadores(stock_data, 'Alto_volume_1.5_?value', 'reversal_uptrend0.03_?value')\n",
    "        # DESLIG stock_data = combine_indicadores(stock_data, 'reversal_uptrend0.03_?value', 'Candlestick_martelo_2,0.1_?value+Alto_volume_1_?value_combine_?value')\n",
    "        # DESLIG stock_data = combine_indicadores(stock_data, 'Candlestick_engolfo_?value', 'Alto_volume_1_?value')\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        Voltará no futuro se achar que comparação com etf ajuda a entender o movimento técnico\n",
    "                       \n",
    "        # Colando os valores macro necessários para o backtest individual e adicionando info de variações\n",
    "        stock_data = adicione_dados_outro_ticker(stock_data, data_cache_macro_tickers[\"BOVA11.SA\"],'Close',\"bova11\")\n",
    "        # adicionar colunas de médias móveis\n",
    "        stock_data = crie_medias_moveis(stock_data, \"BOVA11.SA\", *macro_mme_list)\n",
    "        stock_data = adicione_dados_outro_ticker(stock_data, data_cache_macro_tickers[\"SMAL11.SA\"],'Close',\"smal11\")                                 \n",
    "        # adicionar colunas de médias móveis\n",
    "        stock_data = crie_medias_moveis(stock_data, \"SMAL11.SA\", *macro_mme_list)\n",
    "        \"\"\" \n",
    "\n",
    "        return stock_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96bca0c7-5455-4244-a75e-9a4583ea3c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alto_volume_diario(df, volume_window=20, volume_multiplier=1.5):\n",
    "    \"\"\"\n",
    "    Função que é combinada com outros indicadores, principalmente de candlestick de reversão\n",
    "    Sozinho não é um indicadror relevante. \n",
    "    \n",
    "    Retorna se o volume diário foi superior que a média.\n",
    "\n",
    "    Combinado com o fechamento do dia. Se o volume foi superior e o sinal acompanha a variação do dia.\n",
    "    \n",
    "    -1 para variação negativa.\n",
    "    +1 para positiva.   \n",
    "    \n",
    "    Análises de candle são mais eficientes se confirmarem bom volume de negociações no dia.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Cálculo da média de volume para o período definido.\n",
    "    df['Vol_media'] = df['Volume'].rolling(window=volume_window, min_periods=20).mean()\n",
    "\n",
    "    df[f'Alto_volume_{volume_multiplier}_?value'] = where(df['Volume'] >= df['Vol_media'] * volume_multiplier * (1 - tolerancia_erro),\n",
    "        where(df['Return'] < 0, -1, where(df['Return'] > 0, 1, 0)),\n",
    "        0\n",
    "    )       \n",
    "    \n",
    "    # Remove a coluna auxiliar de volume\n",
    "    df.drop(columns=['Vol_media'], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def up_or_down_trend(df, trend_pct=0.03, trending_days=5):\n",
    "    \"\"\"\n",
    "    Função que é combinada com outros indicadores, principalmente de candlestick de reversão\n",
    "    Sozinho não é um indicadror relevante. \n",
    "    Famoso caiu porque subiu\n",
    "    \"\"\"\n",
    "\n",
    "    # Inicializando as colunas\n",
    "    df[f'reversal_uptrend{trend_pct}_?value'] = df[f'uptrend_following{trend_pct}_?value'] = 0\n",
    "    df[f'reversal_downtrend{trend_pct}_?value'] = df[f'downtrend_following{trend_pct}_?value'] = 0\n",
    "\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "\n",
    "        close = df.iloc[i]['Adj Close']\n",
    "\n",
    "        # Verifica a condição de tendência usando os valores de trending_days dias atrás.\n",
    "        downtrend = False\n",
    "        uptrend = False\n",
    "        days = 0\n",
    "\n",
    "        if i >= 1:\n",
    "\n",
    "            # Primeiro descobre se rolou algum movimento significativo nos últimos trendig_days dias\n",
    "            while days <= trending_days and not (downtrend or uptrend):\n",
    "                close_days_ago = df.iloc[i - days]['Adj Close']\n",
    "                \n",
    "                # downtrend: fechamento até trend_pct abaixo\n",
    "                if close <= (1 - trend_pct) * close_days_ago * (1 + tolerancia_erro):\n",
    "                    downtrend = True\n",
    "                # uptrend: fechamento até trend_pct acima\n",
    "                elif close >= (1 + trend_pct) * close_days_ago * (1 - tolerancia_erro):\n",
    "                    uptrend = True\n",
    "                else:\n",
    "                    days += 1\n",
    "                    \n",
    "        # Depois assinala no df. Botei separado, porque dentro do while iria ficar assinalando para todos os laços\n",
    "        # Cria os dois indicadores para ver qual tem mais correlação. Se continua o movimento ou se reverte\n",
    "        if downtrend:\n",
    "            df.at[df.index[i], f'reversal_downtrend{trend_pct}_?value'] = 1\n",
    "            df.at[df.index[i], f'downtrend_following{trend_pct}_?value'] = -1\n",
    "\n",
    "        elif uptrend:\n",
    "            df.at[df.index[i], f'reversal_uptrend{trend_pct}_?value'] = -1\n",
    "            df.at[df.index[i], f'uptrend_following{trend_pct}_?value'] = 1\n",
    "\n",
    "        # else permanece zero\n",
    "    \n",
    "    return df\n",
    "    \n",
    "\n",
    "def candlestick_martelo(df, wick_pct=2, head_pct=0.1):\n",
    "    \"\"\"\n",
    "    Para cada candle (linha do DataFrame), verifica se o padrão corresponde a um martelo (hammer/takuri)\n",
    "    e cria duas colunas:\n",
    "      - \"Candlestick_martelo\": \"Compra\" se o candle com martelo surgir após uma tendência de baixa,\n",
    "        \"Venda\" se o martelo ocorrer após uma tendência de alta e, caso contrário, \"Neutro\".\n",
    "      - \"sinal\": 1 para sinal de compra, -1 para sinal de venda e NaN para os demais casos.\n",
    "      \n",
    "    Critérios:\n",
    "      1. O candle deve ter uma sombra (inferior ou superior) >= 2.5 vezes o tamanho do corpo \n",
    "         e a sombra oposta deve ser irrisória (<= 0.3 vezes o corpo).\n",
    "      2. Deve surgir após um movimento significativo:\n",
    "         - Tendência de baixa: fechamento atual <= (downtrend_pct) × fechamento de 3 dias atrás.\n",
    "         - Tendência de alta: fechamento atual >= 1.03 × fechamento de 3 dias atrás.\n",
    "      3. O volume do candle deve ser maior que a média dos últimos 'volume_window' dias.\n",
    "    \"\"\"\n",
    "    df = df.copy() # para não dar erro de modificar o df \n",
    "\n",
    "    for i in range(len(df)):\n",
    "        # Valores do candle atual\n",
    "        open_ = df.iloc[i]['Open']\n",
    "        close = df.iloc[i]['Adj Close']\n",
    "        high = df.iloc[i]['High']\n",
    "        low = df.iloc[i]['Low']\n",
    "        \n",
    "        # Calcula o tamanho do corpo e das sombras\n",
    "        body = abs(close - open_)\n",
    "        total_range = high - low\n",
    "        lower_shadow = min(open_, close) - low\n",
    "        upper_shadow = high - max(open_, close)\n",
    "        \n",
    "        # Inicializa a condição de padrão de martelo\n",
    "        forma_martelo_long = False\n",
    "        forma_martelo_short = False\n",
    "        \n",
    "        if body > 0:\n",
    "            # Martelo normal: longa sombra inferior e sombra superior pequena\n",
    "            if lower_shadow >= wick_pct * body * (1 - tolerancia_erro) and upper_shadow <= head_pct * body * (1 + tolerancia_erro):\n",
    "                forma_martelo_long = True\n",
    "            # Martelo invertido: longa sombra superior e sombra inferior pequena\n",
    "            elif upper_shadow >= wick_pct * body * (1 - tolerancia_erro) and lower_shadow <= head_pct * body * (1 + tolerancia_erro):\n",
    "                forma_martelo_short = True        \n",
    "        \n",
    "        # Se o candle preenche o padrão de martelo e tem volume acima da média,\n",
    "        # verifica a tendência para sinalizar:\n",
    "        if forma_martelo_long:\n",
    "            df.at[df.index[i], f'Candlestick_martelo_{wick_pct},{head_pct}_?value'] = 1\n",
    "                \n",
    "        elif forma_martelo_short:    \n",
    "            df.at[df.index[i], f'Candlestick_martelo_{wick_pct},{head_pct}_?value'] = -1\n",
    "            \n",
    "        else:\n",
    "            df.at[df.index[i], f'Candlestick_martelo_{wick_pct},{head_pct}_?value'] = 0\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def candlestick_engolfo(df):\n",
    "    \"\"\"\n",
    "    Para cada candle do DataFrame, identifica:\n",
    "      - Engolfo de Alta (Bullish Engulfing) após queda → sinal +1\n",
    "      - Engolfo de Baixa (Bearish Engulfing) após alta → sinal -1\n",
    "    Insere na coluna 'Candlestick_engolfo' esses sinais, ou NaN caso contrário.\n",
    "    \n",
    "    Critérios para Engolfo de Alta (Bullish Engulfing) [Investopedia]:\n",
    "      1. Candle anterior de baixa (Close < Open).\n",
    "      2. Candle atual de alta (Close > Open).\n",
    "      3. Abertura atual < Fechamento anterior E Fechamento atual > Abertura anterior  \n",
    "         (“engulfa” o corpo do candle anterior) :contentReference[oaicite:0]{index=0}.\n",
    "      4. Deve ocorrer após um movimento de queda de pelo menos `trend_pct` em até `trending_days` atrás.\n",
    "\n",
    "    Critérios para Engolfo de Baixa (Bearish Engulfing) [Investopedia]:\n",
    "      1. Candle anterior de alta (Close > Open).\n",
    "      2. Candle atual de baixa (Close < Open).\n",
    "      3. Abertura atual > Fechamento anterior E Fechamento atual < Abertura anterior  \n",
    "         (“engulfa” o corpo do candle anterior) :contentReference[oaicite:1]{index=1}.\n",
    "      4. Deve ocorrer após um movimento de alta de pelo menos `trend_pct` em até `trending_days` atrás.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    col = 'Candlestick_engolfo_?value'\n",
    "    df[col] = 0\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        \n",
    "        prev_open  = df.iloc[i-1]['Open']\n",
    "        prev_close = df.iloc[i-1]['Adj Close']\n",
    "        curr_open  = df.iloc[i  ]['Open']\n",
    "        curr_close = df.iloc[i  ]['Adj Close']\n",
    "\n",
    "        # Detecta engolfo de alta\n",
    "        is_bullish_engulfing = (\n",
    "            prev_close < prev_open * (1 + tolerancia_erro) and           # anterior de baixa\n",
    "            curr_close > curr_open * (1 - tolerancia_erro) and           # atual de alta\n",
    "            curr_open  < prev_close * (1 + tolerancia_erro) and          # engolfa abertura anterior\n",
    "            curr_close > prev_open * (1 - tolerancia_erro)               # engolfa fechamento anterior\n",
    "        )\n",
    "\n",
    "        # Detecta engolfo de baixa\n",
    "        is_bearish_engulfing = (\n",
    "            prev_close > prev_open and\n",
    "            curr_close < curr_open and\n",
    "            curr_open  > prev_close and\n",
    "            curr_close < prev_open\n",
    "        )\n",
    "        \n",
    "\n",
    "        # Sinaliza conforme padrão + tendência\n",
    "        if is_bullish_engulfing:\n",
    "            df.at[df.index[i], col] =  1\n",
    "        elif is_bearish_engulfing:\n",
    "            df.at[df.index[i], col] = -1\n",
    "            \n",
    "        # Caso contrário, permanece 0\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def calcule_exaustao_atr(df, atr_period=14, multiplier=1.5):\n",
    "    \"\"\"\n",
    "    Calcula o ATR (Average True Range) e verifica se o movimento (True Range) do candle atual\n",
    "    é, pelo menos, 'multiplier' vezes maior que o ATR do dia anterior.\n",
    "    \n",
    "    Se sim, adiciona \"1\" na coluna \"Exaustao ATR\", caso contrário, NaN.\n",
    "    \n",
    "    Parâmetros:\n",
    "      - atr_period: período em dias para cálculo da média (padrão 14).\n",
    "      - multiplier: fator multiplicador para definir “movimento forçado” (padrão 1.5).\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "        \n",
    "    # True Range (TR): a maior entre (High - Low), |High - prev_Close| e |Low - prev_Close|\n",
    "    # Fechamento do dia anterior - df['Adj Close'].shift(1)\n",
    "    df['TR'] = maximum(df['High'] - df['Low'],\n",
    "               maximum(abs(df['High'] - df['Adj Close'].shift(1)), abs(df['Low'] - df['Adj Close'].shift(1))))\n",
    "    \n",
    "    # Cálculo do ATR: média móvel simples do TR, com janela definida por atr_period\n",
    "    df['ATR'] = df['TR'].rolling(window=atr_period).mean()\n",
    "    \n",
    "    # Se o TR do candle atual for pelo menos \"multiplier\" vezes maior que o ATR do dia anterior,\n",
    "    # então:\n",
    "    # - Se df['Return'] for negativo, atribui -1 (movimento forçado de baixa).\n",
    "    # - Se df['Return'] for positivo, atribui 1 (movimento forçado de alta).\n",
    "    # Caso contrário, atribui 0.\n",
    "    \n",
    "    df['Exaustao ATR_?value'] = where(\n",
    "        df['TR'] >= multiplier * df['ATR'].shift(1) * (1 - tolerancia_erro),\n",
    "        where(df['Return'] < 0, -1, where(df['Return'] > 0, 1, 0)),\n",
    "        0\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_mma_direction(stock_data, mma_list):\n",
    "    \"\"\"\n",
    "    Função para adicionar _?value analisys ao df, além de distância do close price para a média móvel 200 dias\n",
    "    \n",
    "    \"\"\"     \n",
    "    \n",
    "    # Cruzamentos de MMA com np.where\n",
    "    '''\n",
    "    stock_data[f'MMA9/MMA26_?value'] = where(\n",
    "        (stock_data[f'MMA26'] < stock_data[f'MMA9'] * (1 + tolerancia_erro)) & stock_data[f'MMA26'].notna() & stock_data[f'MMA9'].notna(), \n",
    "        1, \n",
    "        where(\n",
    "            (stock_data[f'MMA26'] > stock_data[f'MMA9'] * (1 - tolerancia_erro)) & stock_data[f'MMA26'].notna() & stock_data[f'MMA9'].notna(),\n",
    "            -1,\n",
    "            nan\n",
    "        )\n",
    "    )\n",
    "    '''\n",
    "    for deno in mma_list: # DENOminador\n",
    "        for num in mma_list: # Numerador\n",
    "            if num < deno:                \n",
    "                stock_data[f'MMA{num}/MMA{deno}_?value'] = where(\n",
    "                    (stock_data[f'MMA{deno}'] < stock_data[f'MMA{num}'] * (1 + tolerancia_erro)) & stock_data[f'MMA{deno}'].notna() & stock_data[f'MMA{num}'].notna(), \n",
    "                    1, \n",
    "                    where(\n",
    "                        (stock_data[f'MMA{deno}'] > stock_data[f'MMA{num}'] * (1 - tolerancia_erro)) & stock_data[f'MMA{deno}'].notna() & stock_data[f'MMA{num}'].notna(),\n",
    "                        -1,\n",
    "                        nan\n",
    "                    )\n",
    "                )\n",
    "        \n",
    "    # MA e Preço\n",
    "    for mma in mma_list:\n",
    "        \n",
    "        stock_data[f'Price_MMA{mma}_?value'] = where(\n",
    "            (stock_data[f'MMA{mma}'] < stock_data['Adj Close'] * (1 + tolerancia_erro)) & stock_data[f'MMA{mma}'].notna() & stock_data['Adj Close'].notna(), \n",
    "            1, \n",
    "            where(\n",
    "                (stock_data[f'MMA{mma}'] > stock_data['Adj Close'] * (1 - tolerancia_erro)) & stock_data[f'MMA{mma}'].notna() & stock_data['Adj Close'].notna(),\n",
    "                -1,\n",
    "                nan\n",
    "            )\n",
    "        )\n",
    "            \n",
    "    return stock_data\n",
    "\n",
    "\n",
    "def create_mma_position(df, mma_list):\n",
    "    \"\"\"\n",
    "    Função para controlar o momento do papel, de curto, médio e longos prazos.\n",
    "    Se ele está acima ou abaixo da mma. Combinado com outros indicadores, qual tem melhor correlação. \n",
    "    \n",
    "    \"\"\"       \n",
    "    \n",
    "    # Position\n",
    "    for mma in mma_list:\n",
    "\n",
    "        # Cria variáveis \n",
    "        df[f'Position_mma_over{mma}_?value'] = df[f'Position_mma_bellow{mma}_?value'] = 0\n",
    "        \n",
    "        df[f'Position_mma_over{mma}_?value'] = where(\n",
    "            (df[f'MMA{mma}'] < df['Adj Close'] * (1 + tolerancia_erro)) & df[f'MMA{mma}'].notna() & df['Adj Close'].notna(), \n",
    "            1, \n",
    "            where(\n",
    "                (df[f'MMA{mma}'] > df['Adj Close'] * (1 - tolerancia_erro)) & df[f'MMA{mma}'].notna() & df['Adj Close'].notna(),\n",
    "                -1,\n",
    "                0\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Inverte o indicador\n",
    "        df[f'Position_mma_bellow{mma}_?value'] = where(df[f'Position_mma_over{mma}_?value'] == 1, -1,\n",
    "            where(df[f'Position_mma_over{mma}_?value'] == -1, 1, 0))\n",
    "                                                       \n",
    "            \n",
    "    return df\n",
    "\n",
    "def calculate_obv(stock_data):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Inicializando a lista OBV com o primeiro valor como 0\n",
    "    obv = [0]\n",
    "    \n",
    "    # Iterando sobre os preços de fechamento e volumes\n",
    "    for i in range(1, len(stock_data['Adj Close'])):\n",
    "        if stock_data['Adj Close'].iloc[i] > stock_data['Adj Close'].iloc[i-1]:\n",
    "            # Se o preço de fechamento atual é maior que o anterior, adicionar o volume\n",
    "            obv.append(obv[-1] + stock_data['Volume'].iloc[i])\n",
    "        elif stock_data['Adj Close'].iloc[i] < stock_data['Adj Close'].iloc[i-1]:\n",
    "            # Se o preço de fechamento atual é menor que o anterior, subtrair o volume\n",
    "            obv.append(obv[-1] - stock_data['Volume'].iloc[i])\n",
    "        else:\n",
    "            # Se o preço de fechamento é igual ao anterior, OBV não muda\n",
    "            obv.append(obv[-1])\n",
    "            \n",
    "    # Adicionar a coluna OBV ao DataFrame\n",
    "    stock_data['OBV'] = obv\n",
    "    \n",
    "    # Calcular o OBV para todas as mma_list\n",
    "    # Fiz o código para calcular obv para toda a mma. Mas acho que em se tratando de volume, não faz sentido olhar obv_MA_50/200days\n",
    "    for window in [10, 20]: #mma_list: \n",
    "        \n",
    "        stock_data[f'OBV_MA_{window}days'] = stock_data['OBV'].rolling(window=window).mean()\n",
    "    \n",
    "        # Atribuindo value\n",
    "        stock_data[f'OBV_{window}d_?value'] = [1 if stock_data['OBV'].iloc[i] > stock_data[f'OBV_MA_{window}days'].iloc[i] else -1 for i in range(len(stock_data))]\n",
    "    \n",
    "        # Apagando colunas desnecessárias\n",
    "        stock_data.drop(columns=[f'OBV_MA_{window}days'], inplace=True)\n",
    "    \n",
    "    return stock_data\n",
    "\n",
    "def adicione_dados_outro_ticker(stock_data, df_added, col_name, col_rename=\"Nova coluna\"):\n",
    "    \"\"\"\n",
    "    Função que faz merge de uma coluna do df_added ao stock_data\n",
    "    \n",
    "    Col_name = Nome da coluna que entrará no merge\n",
    "    col_rename = Quase sempre, para evitar conflito, será necessário mudar o nome da coluna\n",
    "    \n",
    "    \"\"\"\n",
    "    # Isolando a coluna que irá para o merge\n",
    "    df_added = df_added[[col_name]]\n",
    "\n",
    "    # trocando o nome da coluna para o merge não ficar com nomes em duplicidade\n",
    "    df_added_col_renamed = df_added.rename(columns={col_name: col_rename})    \n",
    "    \n",
    "    # Realizando o merge com base na coluna 'Date'\n",
    "    stock_data = pandas.merge(stock_data, df_added_col_renamed, on='Date', how='outer')\n",
    "    \n",
    "    return stock_data\n",
    "\n",
    "\n",
    "def calcule_vwap(dados):\n",
    "    \n",
    "    # Calcular o VWAP\n",
    "    dados['VWAP'] = (dados['Adj Close'] * dados['Volume']).cumsum() / dados['Volume'].cumsum()\n",
    "\n",
    "    # Sinal de compra/venda baseado na comparação do preço de fechamento com o VWAP\n",
    "    dados['Sinal_Num'] = where(dados['Adj Close'] > dados['VWAP'] * (1 + tolerancia_erro), 1, \n",
    "                              where(dados['Adj Close'] < dados['VWAP'] * (1 + tolerancia_erro), -1, 0))\n",
    "  \n",
    "    # Calcular a soma em uma janela deslizante de 20 dias\n",
    "    for window in [20]: \n",
    "        dados[f'Soma_Sinal_{window}d'] = dados['Sinal_Num'].rolling(window=window, min_periods=1).sum()\n",
    "    \n",
    "        # Determinar o sinal baseado na soma: Se a maioria é compra (>0), venda (<0), ou neutro (==0)\n",
    "        dados[f'VWAP_Sinal_{window}d_?value'] = select(\n",
    "            [\n",
    "                dados[f'Soma_Sinal_{window}d'] > 0, \n",
    "                dados[f'Soma_Sinal_{window}d'] <= 0\n",
    "            ], \n",
    "            [1,-1])\n",
    "    \n",
    "        # Apagar coluna desnecessária\n",
    "        dados.drop(columns=[f'Soma_Sinal_{window}d'], inplace=True)\n",
    "\n",
    "    # Apagar coluna desnecessária\n",
    "    dados.drop(columns=['Sinal_Num'], inplace=True)\n",
    "        \n",
    "    return dados\n",
    "\n",
    "\n",
    "def calculate_rsi(dados, rsi_window=14):\n",
    "    \"\"\"\n",
    "    Horrível\n",
    "    corr de -0,004 a -0,07\n",
    "    \"\"\"\n",
    "    delta = dados['Adj Close'].diff()\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "\n",
    "    avg_gain = gain.rolling(window=rsi_window, min_periods=1).mean()\n",
    "    avg_loss = loss.rolling(window=rsi_window, min_periods=1).mean()\n",
    "\n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "\n",
    "    dados[f'RSI_{rsi_window}days'] = rsi\n",
    "\n",
    "    # Atribuindo _?value\n",
    "    dados[f'RSI_{rsi_window}days_?value'] = dados[f'RSI_{rsi_window}days'].apply(lambda x: 1 if x <= 30 else -1 )    \n",
    "    \n",
    "    return dados\n",
    "\n",
    "def calculate_stocastic(dados):\n",
    "    '''\n",
    "    '''\n",
    "   \n",
    "    # Cálculo do Estocástico Lento (14, 3, 3)\n",
    "    estocastico = pandas_ta.stoch(dados['High'], dados['Low'], dados['Adj Close'], k=14, d=3, smooth_k=3)\n",
    "    dados['SlowK'] = estocastico['STOCHk_14_3_3']\n",
    "    dados['SlowD'] = estocastico['STOCHd_14_3_3']\n",
    "\n",
    "    # Inicializar coluna de sinais de compra/venda\n",
    "    dados['estocastico_?value'] = 0\n",
    "\n",
    "    # Condições para sinais de compra e venda\n",
    "    for i in range(1, len(dados)):\n",
    "        # Sinal de Compra: %K cruza acima de %D e ambos estão abaixo de 20\n",
    "        if dados['SlowK'].iloc[i-1] < dados['SlowD'].iloc[i-1] and dados['SlowK'].iloc[i] > dados['SlowD'].iloc[i] and dados['SlowK'].iloc[i] < 20:\n",
    "            dados.loc[dados.index[i], 'estocastico_?value'] = 1\n",
    "        \n",
    "        # Sinal de Venda: %K cruza abaixo de %D e ambos estão acima de 80\n",
    "        elif dados['SlowK'].iloc[i-1] > dados['SlowD'].iloc[i-1] and dados['SlowK'].iloc[i] < dados['SlowD'].iloc[i] and dados['SlowK'].iloc[i] > 80:\n",
    "            dados.loc[dados.index[i], 'estocastico_?value'] = -1\n",
    "\n",
    "    return dados\n",
    "\n",
    "def adx_prblc_sar_trigger_strtg(dados):\n",
    "    \"\"\"\n",
    "    7. ADX + Parabolic SAR\n",
    "    Trigger de Compra: Se o ADX (Índice de Direcional Médio) está acima de 25, e o Parabolic SAR gera um ponto abaixo do preço, é uma indicação de tendência de alta forte.\n",
    "    Trigger de Venda: Se o ADX está acima de 25 e o Parabolic SAR gera um ponto acima do preço, sinaliza uma tendência de baixa forte.\n",
    "    Combinação de Indicadores:\n",
    "    ADX (14 períodos)\n",
    "    Parabolic SAR (configurações padrão)\n",
    "    \"\"\"\n",
    "    # Cálculo do ADX (14 períodos)\n",
    "    adx = pandas_ta.adx(dados['High'], dados['Low'], dados['Adj Close'], length=14)\n",
    "    dados['ADX'] = adx['ADX_14']\n",
    "\n",
    "    # Cálculo do Parabolic SAR\n",
    "    psar = pandas_ta.psar(dados['High'], dados['Low'], dados['Adj Close'])\n",
    "    dados['SAR'] = psar['PSARl_0.02_0.2']  # \"l\" de \"lower\" para valores de suporte\n",
    "\n",
    "    # Inicializar a coluna 'signal' para guardar os sinais de compra/venda\n",
    "    dados['adx_sar_?value'] = 0\n",
    "\n",
    "    # Condições para sinais de compra e venda\n",
    "    for i in range(1, len(dados)):\n",
    "        # Sinal de Compra: Preço cruza acima do Parabolic SAR e ADX maior que 25\n",
    "        if dados['Adj Close'].iloc[i] > dados['SAR'].iloc[i] and dados['ADX'].iloc[i] > 25:\n",
    "            dados.loc[dados.index[i], 'adx_sar_?value'] = 1\n",
    "        \n",
    "        # Sinal de Venda: Preço cruza abaixo do Parabolic SAR e ADX maior que 25\n",
    "        elif dados['Adj Close'].iloc[i] < dados['SAR'].iloc[i] and dados['ADX'].iloc[i] > 25:\n",
    "            dados.loc[dados.index[i], 'adx_sar_?value'] = -1\n",
    "\n",
    "    return dados\n",
    "\n",
    "def calculate_ichimoku(data):\n",
    "    \"\"\"\n",
    "    Função para calcular os componentes da Nuvem Ichimoku e os sinais de compra/venda.\n",
    "    \"\"\"\n",
    "    # Calcular a Linha de Conversão (Tenkan-sen) para cada linha do DataFrame\n",
    "    data['Tenkan_sen'] = (data['High'].rolling(window=9).max() + data['Low'].rolling(window=9).min()) / 2\n",
    "\n",
    "    # Calcular a Linha de Base (Kijun-sen) para cada linha do DataFrame\n",
    "    data['Kijun_sen'] = (data['High'].rolling(window=26).max() + data['Low'].rolling(window=26).min()) / 2\n",
    "\n",
    "    # Calcular Senkou Span A (primeiro componente da nuvem) e deslocar 26 períodos para frente\n",
    "    data['Senkou_span_A'] = ((data['Tenkan_sen'] + data['Kijun_sen']) / 2).shift(26)\n",
    "\n",
    "    # Calcular Senkou Span B (segundo componente da nuvem) e deslocar 26 períodos para frente\n",
    "    data['Senkou_span_B'] = (data['High'].rolling(window=52).max() + data['Low'].rolling(window=52).min()) / 2\n",
    "    data['Senkou_span_B'] = data['Senkou_span_B'].shift(26)\n",
    "\n",
    "    # Calcular a Linha Chikou (Lagging Span) e deslocar 26 períodos para trás\n",
    "    data['Chikou_span'] = data['Adj Close'].shift(-26)\n",
    "\n",
    "    # Inicializar a coluna 'ichimoku_signal' com 0 (Hold)\n",
    "    data['ichimoku_?value'] = 0\n",
    "\n",
    "    # Sinal de Compra: Preço de fechamento acima da nuvem e Tenkan-sen acima da Kijun-sen\n",
    "    data['ichimoku_?value'] = where(\n",
    "        (data['Adj Close'] > data[['Senkou_span_A', 'Senkou_span_B']].max(axis=1)) & \n",
    "        (data['Tenkan_sen'] > data['Kijun_sen']), \n",
    "        1, \n",
    "        data['ichimoku_?value']\n",
    "    )\n",
    "\n",
    "    # Sinal de Venda: Preço de fechamento abaixo da nuvem e Tenkan-sen abaixo da Kijun-sen\n",
    "    data['ichimoku_?value'] = where(\n",
    "        (data['Adj Close'] < data[['Senkou_span_A', 'Senkou_span_B']].min(axis=1)) & \n",
    "        (data['Tenkan_sen'] < data['Kijun_sen']), \n",
    "        -1, \n",
    "        data['ichimoku_?value']\n",
    "    )\n",
    "\n",
    "    return data\n",
    "    \n",
    "\n",
    "def calcule_volatilidade_anualizada(dados, vol_window):\n",
    "    \"\"\"\n",
    "    Calcula a volatilidade anualizada com uma janela móvel para os retornos logarítmicos.\n",
    "\n",
    "    Args:\n",
    "    dados (DataFrame): DataFrame contendo os preços com uma coluna 'Return' para os retornos diários logarítmicos.\n",
    "    vol_window (int): Janela de tempo em dias para o cálculo da volatilidade móvel.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: O mesmo DataFrame de entrada com uma nova coluna adicionada para a volatilidade anualizada.\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Volatilidade anualizada para comparação com outros ativos\n",
    "    dados[f'vol_anualized_{vol_window}days'] = dados['Return'].rolling(window=vol_window, min_periods=1).std() * sqrt(252)\n",
    "    \n",
    "    # Calculando média e std da volatilidade para saber quando o ticker está mudando de patamar de risco \n",
    "    # Garantindo que só calculamos média e std se houver dados suficientes\n",
    "    dados['media_vol_200d'] = where(dados['Return'].rolling(window=200, min_periods=200).count() >= 200,\n",
    "                                       dados[f'vol_anualized_{vol_window}days'].rolling(window=200).mean(),\n",
    "                                       0)\n",
    "    dados['std_vol_200d'] = where(dados['Return'].rolling(window=200, min_periods=200).count() >= 200,\n",
    "                                     dados[f'vol_anualized_{vol_window}days'].rolling(window=200).std(),\n",
    "                                     0)\n",
    "    \n",
    "    # Analisando a variação de volatilidade do ativo para saber se o risco está aumentando\n",
    "    dados['change_in_volatility_?value'] = where(dados['media_vol_200d'].notna() & dados['std_vol_200d'].notna(),\n",
    "                                           where(dados[f'vol_anualized_{vol_window}days'] > dados['media_vol_200d'] + dados['std_vol_200d'], 1,\n",
    "                                                    where(dados[f'vol_anualized_{vol_window}days'] < dados['media_vol_200d'] - dados['std_vol_200d'], -1, 0)),\n",
    "                                           0)\n",
    "    \n",
    "        \n",
    "    dados.drop(columns=['media_vol_200d','std_vol_200d'], inplace=True)\n",
    "  \n",
    "    return dados\n",
    "\n",
    "def calculate_cci(df, window=20):\n",
    "    \"\"\"\n",
    "    Calcula o Commodity Channel Index (CCI) para os preços fornecidos e gera sinais de negociação.\n",
    "    \n",
    "    Parâmetros:\n",
    "    - df: DataFrame contendo os preços com colunas ['High', 'Low', 'Adj Close'].\n",
    "    - window: O período para calcular o CCI. Padrão é 20.\n",
    "\n",
    "    Retorna:\n",
    "    - DataFrame com a coluna 'CCI' e 'CCI_Signal' (1 para compra, -1 para venda, 0 para neutro).\n",
    "    \"\"\"\n",
    "    # Calcular o Typical Price (Preço Típico)\n",
    "    df['Typical_Price'] = (df['High'] + df['Low'] + df['Adj Close']) / 3\n",
    "\n",
    "    # Calcular a Média Móvel do Preço Típico\n",
    "    df['TP_MA'] = df['Typical_Price'].rolling(window=window).mean()\n",
    "\n",
    "    # Calcular o Desvio Médio do Preço Típico\n",
    "    df['TP_Deviation'] = df['Typical_Price'].rolling(window=window).apply(lambda x: mean(abs(x - mean(x))), raw=True)\n",
    "\n",
    "    # Calcular o CCI\n",
    "    df['CCI'] = (df['Typical_Price'] - df['TP_MA']) / (0.015 * df['TP_Deviation'])\n",
    "\n",
    "    # Inicializar a coluna de sinal como 0\n",
    "    df['CCI_?value'] = 0\n",
    "\n",
    "    # Sinal de Compra: CCI cruza acima de -100\n",
    "    df['CCI_?value'] = where(df['CCI'] > -100, 1, df['CCI_?value'])\n",
    "\n",
    "    # Sinal de Venda: CCI cruza abaixo de 100\n",
    "    df['CCI_?value'] = where(df['CCI'] < 100, -1, df['CCI_?value'])\n",
    "\n",
    "    # Limpar colunas temporárias\n",
    "    df.drop(['Typical_Price', 'TP_MA', 'TP_Deviation'], axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def bollinger_keltner_squeeze(df, window=20):\n",
    "    \"\"\"\n",
    "    Calcula o Bollinger Squeeze usando Bandas de Bollinger e Canais de Keltner.\n",
    "    \n",
    "    Parâmetros:\n",
    "    - df: DataFrame contendo os preços com a coluna 'Adj Close'.\n",
    "    - window: O período para calcular as Bandas de Bollinger e os Canais de Keltner. Padrão é 20.\n",
    "\n",
    "    Retorna:\n",
    "    - DataFrame com colunas 'Bollinger_Squeeze' para sinais de negociação: \n",
    "      1 para compra, -1 para venda, e 0 para neutro.\n",
    "    \"\"\"\n",
    "    # Calcular a Média Móvel Simples (SMA) e o Desvio Padrão para as Bandas de Bollinger\n",
    "    df['SMA'] = df['Adj Close'].rolling(window=window).mean()\n",
    "    df['STD'] = df['Adj Close'].rolling(window=window).std()\n",
    "    \n",
    "    # Calcular as Bandas de Bollinger\n",
    "    df['Bollinger_Upper'] = df['SMA'] + 2 * df['STD']\n",
    "    df['Bollinger_Lower'] = df['SMA'] - 2 * df['STD']\n",
    "    \n",
    "    # Calcular a Média Móvel Exponencial (EMA) para os Canais de Keltner\n",
    "    df['EMA'] = df['Adj Close'].ewm(span=window, adjust=False).mean()\n",
    "    \n",
    "    # Calcular o True Range e o ATR para os Canais de Keltner\n",
    "    df['High_Low'] = df['High'] - df['Low']\n",
    "    df['High_Close'] = abs(df['High'] - df['Adj Close'].shift(1))\n",
    "    df['Low_Close'] = abs(df['Low'] - df['Adj Close'].shift(1))\n",
    "    df['True_Range'] = df[['High_Low', 'High_Close', 'Low_Close']].max(axis=1)\n",
    "    df['ATR'] = df['True_Range'].rolling(window=window).mean()\n",
    "    \n",
    "    # Calcular os Canais de Keltner\n",
    "    df['Keltner_Upper'] = df['EMA'] + 1.5 * df['ATR']\n",
    "    df['Keltner_Lower'] = df['EMA'] - 1.5 * df['ATR']\n",
    "    \n",
    "    # Calcular o Bollinger Squeeze\n",
    "    df['Squeeze'] = ((df['Bollinger_Upper'] < df['Keltner_Upper']) & \n",
    "                     (df['Bollinger_Lower'] > df['Keltner_Lower'])).astype(int)\n",
    "    \n",
    "    # Inicializar a coluna de sinal como 0\n",
    "    df['Bollinger_Squeeze_?value'] = 0\n",
    "\n",
    "    # Sinal de Compra: O squeeze está presente e o preço rompe acima da banda superior de Bollinger\n",
    "    df['Bollinger_Squeeze_?value'] = where(\n",
    "        (df['Squeeze'] == 1) & (df['Adj Close'] > df['Bollinger_Upper']), \n",
    "        1, \n",
    "        df['Bollinger_Squeeze_?value']\n",
    "    )\n",
    "\n",
    "    # Sinal de Venda: O squeeze está presente e o preço rompe abaixo da banda inferior de Bollinger\n",
    "    df['Bollinger_Squeeze_?value'] = where(\n",
    "        (df['Squeeze'] == 1) & (df['Adj Close'] < df['Bollinger_Lower']), \n",
    "        -1, \n",
    "        df['Bollinger_Squeeze_?value']\n",
    "    )\n",
    "\n",
    "    # Limpar colunas temporárias\n",
    "    df.drop(['SMA', 'STD', 'Bollinger_Upper', 'Bollinger_Lower', 'EMA', \n",
    "             'High_Low', 'High_Close', 'Low_Close', 'True_Range', 'ATR', \n",
    "             'Keltner_Upper', 'Keltner_Lower', 'Squeeze'], axis=1, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def calculate_volume_profile(df, period=200, num_bins=40):\n",
    "    \"\"\"\n",
    "    Calcula o Volume Profile para um período específico e gera sinais de compra/venda.\n",
    "    \n",
    "    Parâmetros:\n",
    "    - df: DataFrame contendo os preços com as colunas 'High', 'Low', 'Adj Close', e 'Volume'.\n",
    "    - period: O período para análise de swing trade (em dias). Padrão é 30 dias.\n",
    "    - num_bins: Número de faixas de preço (bins) para calcular o volume profile. Padrão é 20.\n",
    "\n",
    "    Retorna:\n",
    "    - DataFrame com colunas 'Volume_Profile_Signal' contendo 1 (compra), -1 (venda), ou 0 (neutro).\n",
    "    \"\"\"\n",
    "    # Inicializar listas para armazenar hvn_price e lvn_price\n",
    "    hvn_prices = [nan] * len(df)\n",
    "    lvn_prices = [nan] * len(df)\n",
    "\n",
    "    # Inicializar a coluna de sinais\n",
    "    df['hvn_price'] = 0\n",
    "    df['lvn_price'] = 0\n",
    "    df['Volume_Profile_?value'] = 0\n",
    "\n",
    "    # Iterar sobre o DataFrame para calcular o Volume Profile em cada janela de tempo de 'period' dias\n",
    "    for i in range(period, len(df)):\n",
    "        # Selecionar a janela de tempo para a análise\n",
    "        data_slice = df.iloc[i-period:i]\n",
    "        \n",
    "        # Calcular o preço máximo e mínimo no período\n",
    "        price_min = data_slice['Low'].min()\n",
    "        price_max = data_slice['High'].max()\n",
    "        \n",
    "        # Criar bins de preço para o volume profile\n",
    "        price_bins = linspace(price_min, price_max, num_bins)\n",
    "        \n",
    "        # Inicializar o volume profile\n",
    "        volume_profile = zeros(len(price_bins) - 1)\n",
    "        \n",
    "        # Calcular o volume profile\n",
    "        for j in range(len(price_bins) - 1):\n",
    "            # Volume total para cada bin de preço\n",
    "            volume_profile[j] = data_slice[(data_slice['Adj Close'] >= price_bins[j]) & (data_slice['Adj Close'] < price_bins[j+1])]['Volume'].sum()\n",
    "        \n",
    "        # Encontrar os High Volume Node (HVN) e Low Volume Node (LVN)\n",
    "        hvn_index = argmax(volume_profile)\n",
    "        lvn_index = argmin(volume_profile)\n",
    "        \n",
    "        hvn_price = (price_bins[hvn_index] + price_bins[hvn_index + 1]) / 2\n",
    "        lvn_price = (price_bins[lvn_index] + price_bins[lvn_index + 1]) / 2\n",
    "\n",
    "        # Armazenar os valores de hvn_price e lvn_price nas listas\n",
    "        hvn_prices[i] = hvn_price\n",
    "        lvn_prices[i] = lvn_price\n",
    "\n",
    "    # Adicionar as listas como novas colunas no DataFrame\n",
    "    df['hvn_price'] = hvn_prices\n",
    "    df['lvn_price'] = lvn_prices\n",
    "\n",
    "    # Usar where para criar os sinais de compra e venda\n",
    "    df['Volume_Profile_?value'] = where(\n",
    "        (df['Adj Close'] <= df['hvn_price'] * 1.02) & (df['Adj Close'] >= df['hvn_price'] * 0.98), \n",
    "        1, \n",
    "        df['Volume_Profile_?value']\n",
    "    )\n",
    "\n",
    "    df['Volume_Profile_?value'] = where(\n",
    "        (df['Adj Close'] <= df['lvn_price'] * 1.02) & (df['Adj Close'] >= df['lvn_price'] * 0.98), \n",
    "        -1, \n",
    "        df['Volume_Profile_?value']\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43f4a83-7371-458d-a3c7-49483026d618",
   "metadata": {},
   "source": [
    "#### Screeener\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8b32ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_indicadores(df, col1: str, col2: str):\n",
    "    \"\"\"\n",
    "    Cria uma coluna que é a soma de duas colunas (col1 e col2),\n",
    "    nomeada como \"col1+col2_combine_?value\". Em seguida, transforma\n",
    "    todos os 0 em NaN e todos os 2 em 1, percorrendo com um laço.\n",
    "\n",
    "    Parâmetros:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame de entrada.\n",
    "    col1 : str\n",
    "        Nome da primeira coluna.\n",
    "    col2 : str\n",
    "        Nome da segunda coluna.\n",
    "\n",
    "    Retorna:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Mesmo DataFrame de entrada, com a coluna combinada adicionada.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define o nome da nova coluna\n",
    "    new_col = f\"{col1}+{col2}_combine_?value\"\n",
    "\n",
    "    # Soma as duas colunas\n",
    "    df[new_col] = df[col1] + df[col2]\n",
    "\n",
    "    # Loop para ajustar valores\n",
    "    for idx in df.index:\n",
    "        val = df.at[idx, new_col]\n",
    "        if val in (1, -1, 0):\n",
    "            df.at[idx, new_col] = 0\n",
    "        elif val == 2:\n",
    "            df.at[idx, new_col] = 1\n",
    "        elif val == -2:\n",
    "            df.at[idx, new_col] = -1\n",
    "    return df\n",
    "\n",
    "\n",
    "def adicione_variacoes_dataframe(df, days_var_list, operarion_days_per_var_days=3):\n",
    "    \"\"\"\n",
    "    operarion_days_per_var_days é a quantidade de dias que permite por Var_X_days.\n",
    "    Exemplo: as últimas 5 operações com variação de 3 dias \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Adicionando novas colunas para armazenar as variações percentuais\n",
    "    for days in days_var_list:\n",
    "        df[f'Var_{days}d'] = None\n",
    "                           \n",
    "    # Iterando sobre o DataFrame e calculando as variações percentuais\n",
    "    for idx, row in df.iterrows():       \n",
    "\n",
    "        operation_date = str(row['Date']) # O objeto é pandas.datetime. Se não mudar para string a função latest_market_days volta vazia\n",
    "        closing_value = row['Fechamento']\n",
    "        ticker = row['Ticker'] + \".SA\" #Os dados em data_cache_backtest estão com .SA\n",
    "\n",
    "        for days in days_var_list:\n",
    "            \n",
    "            if operation_date >= latest_market_days[- days - operarion_days_per_var_days]:\n",
    "\n",
    "                # Encontrando a data futura\n",
    "                try:\n",
    "                    future_date_str = latest_market_days[latest_market_days.index(operation_date) + days]              \n",
    "                    future_date = pandas.to_datetime(future_date_str) # devolve a data para o objeto datetime            \n",
    "\n",
    "                except (ValueError, IndexError):\n",
    "                    # Se a data futura não estiver disponível, continue para a próxima iteração\n",
    "                    continue\n",
    "\n",
    "                # Encontrando o valor de fechamento futuro\n",
    "                try:             \n",
    "                    future_closing_value = data_cache_backtest[ticker].loc[future_date, 'Adj Close']\n",
    "\n",
    "                except (KeyError, IndexError): # Quando você roda o robo durante a operação, algumas vezes os dados de hoje não estão disponíveis\n",
    "                    print(f'Dados de {ticker} em {future_date.date()} não disponíveis' )\n",
    "                    continue\n",
    "\n",
    "                # Calculando a variação percentual e armazenando no DataFrame\n",
    "                variation = ((future_closing_value - closing_value) / closing_value) * 100\n",
    "                df.at[idx, f'Var_{days}d'] = variation\n",
    "\n",
    "\n",
    "    # Deletando as colunas desnecessárias. Deixam o df muito pesado\n",
    "    for col in df.columns:\n",
    "\n",
    "        if col in latest_market_days:\n",
    "\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "def screener(lista):\n",
    "    '''\n",
    "    Parametros: Lista de tickers\n",
    "                Informação se o dataframe será do dia atual ou para backtest\n",
    "                    \n",
    "    Return: carteira_analise_todos_tickers -> dfs com a soma de todas as últimas linhas de cada extração\n",
    "            absolut_todas_montagens_indicadores_analises -> Todos os dfs somados\n",
    "    '''    \n",
    "    \n",
    "    # Inicializando variváveis \n",
    "    carteira_analise_todos_tickers = pandas.DataFrame()\n",
    "    absolut_todas_montagens_indicadores_analises = pandas.DataFrame()\n",
    "    \n",
    "    for values in tqdm(lista, desc=\"Processando Tickers\"):\n",
    "\n",
    "        # filtro para quando o papel está com algum erro de dados na Yahoo Finance\n",
    "        if values not in probleminhas:\n",
    "\n",
    "            values = f'{values}.SA' # Para atender ao código do ticker no Yfinance\n",
    "\n",
    "            try:\n",
    "    \n",
    "                fechamento_com_todos_indicadores_tecnicos = analisa_tecnicamente_cotacoes(values)\n",
    "\n",
    "    \n",
    "                if not fechamento_com_todos_indicadores_tecnicos.empty:\n",
    "                    \n",
    "                    # Adicionando o ticker às colunas\n",
    "                    fechamento_com_todos_indicadores_tecnicos.insert(0, 'Ticker', values[:-3])    \n",
    "                    # Movendo o index \"data\" para coluna. O Index será ignorado e zerado a seguir\n",
    "                    # Importante porque o backtest usa o método loc, que só funciona com indice em interger\n",
    "                    fechamento_com_todos_indicadores_tecnicos = fechamento_com_todos_indicadores_tecnicos.reset_index()\n",
    "                    # Adicionando dados de retorno da operação para days_list            \n",
    "                    fechamento_com_todos_indicadores_tecnicos_valorizacao = verticalize_preços_fechamento(fechamento_com_todos_indicadores_tecnicos)\n",
    "                    fechamento_com_todos_indicadores_tecnicos_valorizacao_avaliacao = avalie_alta_baixa(fechamento_com_todos_indicadores_tecnicos_valorizacao, days_list)\n",
    "\n",
    "            except:   \n",
    "                   \n",
    "                print(f'Erro ao calcular {values}.')                \n",
    "                if values not in probleminhas_temp:\n",
    "                    probleminhas_temp.append(values)\n",
    "                    continue\n",
    "            \n",
    "            # Adiciona as flags de gatilhos\n",
    "            fechamento_com_todos_indicadores_tecnicos_valorizacao_avaliacao_gatilhos = encontre_gatilhos_persistences(fechamento_com_todos_indicadores_tecnicos_valorizacao_avaliacao, k)\n",
    "            \n",
    "            if test_indicadores:\n",
    "                # INTEGRAÇÃO DOS DFS DE TICKERS\n",
    "                absolut_todas_montagens_indicadores_analises = pandas.concat([absolut_todas_montagens_indicadores_analises, fechamento_com_todos_indicadores_tecnicos_valorizacao_avaliacao_gatilhos], ignore_index=True) \n",
    "\n",
    "\n",
    "                    \n",
    "            # EXPORTAÇÕES \n",
    "            if len(lista) <=2: # Aciona a exportação só se a lista de tickers é pequena\n",
    "                autoriza_exportar = input(f'Exportar arquivo?') # INPUT SERVE SÓ PARA TRAVAR UM ERRO DE BLOQUEIO E CÓDIGO NÃO EXPORTAR 300 DF\n",
    "                fechamento_com_todos_indicadores_tecnicos_valorizacao_avaliacao_gatilhos.to_excel(f'{values}.xlsx')\n",
    "            \n",
    "            # Selecionar a última linha e adicionar a coluna \"Ticker\"\n",
    "            ultima_linha = fechamento_com_todos_indicadores_tecnicos_valorizacao_avaliacao_gatilhos.iloc[[-1]].copy()\n",
    "            \n",
    "            # Gerando df com todas as montagens e adicionando a última linha de cada ticker\n",
    "            if carteira_analise_todos_tickers.empty:\n",
    "                \n",
    "                carteira_analise_todos_tickers = ultima_linha # Empacotando como DataFrame\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                carteira_analise_todos_tickers = pandas.concat([carteira_analise_todos_tickers, ultima_linha], ignore_index=True)  # Passando uma lista de DataFrames                    \n",
    "            \n",
    "    # Se estamos testando indicadores, retorna o df com todos os as montagens.\n",
    "    if test_indicadores:\n",
    "        return carteira_analise_todos_tickers, absolut_todas_montagens_indicadores_analises\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        return carteira_analise_todos_tickers\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee015fd",
   "metadata": {},
   "source": [
    "## Funções do Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "713c1759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avalie_alta_baixa(df, days_list):\n",
    "    \"\"\"\n",
    "    Converte o valor percentual do retorno da operação em uma informação de alta ou baixa.\n",
    "    Ex. A variação em 10 dias foi 0.09. Vai virar 1. A variação de 60 dias foi -0.53. Vira -1.\n",
    "    \"\"\"\n",
    "    for days in days_list:\n",
    "    \n",
    "        df[f'{days}d_?alta'] = where(df[f'{days}d_var_desloc'] > 0, 1, -1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def encontre_gatilhos_persistences(df, k):\n",
    "    \"\"\"\n",
    "    Procura em toda coluna _?value uma mudança de valor. A mudança de valor é um gatilho\n",
    "    Ex. cruzamento de mmas estava 0 ontem, hoje 1. Então a coluna _?gatilho será 1\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Gera todas as séries de gatilho em dict\n",
    "    new_cols = {}\n",
    "    #persistence_ks = 3\n",
    "    persistence_ks = range(3, 4)\n",
    "    delay_days= (2,3,4,5)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if not col.endswith('_?value'):\n",
    "            continue\n",
    "        \n",
    "        # Caso especial: colunas de Position. Exemplo - todas os fechamentos com close acima da mma50\n",
    "        if 'Position' in col:\n",
    "            gat_col = col.replace('_?value', '_position_not_?gatilho')\n",
    "            # atribui cópia inteira da série original\n",
    "            new_cols[gat_col] = df[col].copy()  \n",
    "        \n",
    "        # Caso padrão: sinaliza mudança de valor\n",
    "        else:\n",
    "            gat_col = col.replace('_?value', '_?gatilho')\n",
    "            delta = df[col].diff()\n",
    "            gat = sign(delta).fillna(0).astype(int)\n",
    "            gat[df[col] == 0] = 0           # exclui transições para 0\n",
    "            new_cols[gat_col] = gat\n",
    "\n",
    "            # -------------- persistência k-dias ---------------------------\n",
    "            # streak de valores iguais\n",
    "            streak = (\n",
    "                df[col]\n",
    "                .groupby((df[col] != df[col].shift()).cumsum())\n",
    "                .cumcount() + 1\n",
    "            )\n",
    "\n",
    "            if type(persistence_ks) == int:\n",
    "                pers_col = col.replace(\"_?value\", f\"_?persistence_{k}days\")\n",
    "                # mantém o valor original se a sequência atual >= k dias\n",
    "                new_cols[pers_col] = df[col].where(streak >= k, 0)\n",
    "            \n",
    "            else:\n",
    "               \n",
    "                for k in persistence_ks:\n",
    "                    pers_col = col.replace(\"_?value\", f\"_?persistence_{k}days\")\n",
    "                    # mantém o valor original se a sequência atual >= k dias\n",
    "                    new_cols[pers_col] = df[col].where(streak >= k, 0)\n",
    "\n",
    "            if delay_days != None:\n",
    "                # --- delay_last d dias ---\n",
    "                for d in delay_days:\n",
    "                    delay_col = f\"delay_last{d}days_{gat_col}\"\n",
    "                    roll_sum = gat.rolling(window=d, min_periods=d).sum()\n",
    "                    new_cols[delay_col] = sign(roll_sum).astype('Int8')\n",
    "            \n",
    "    # 2) Concatena explicitamente antes do return\n",
    "    #gat_df = pandas.DataFrame(new_cols, index=df.index)\n",
    "    #df = pandas.concat([df, gat_df], axis=1)\n",
    "    df[list(new_cols)] = pandas.DataFrame(new_cols, index=df.index)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "'''\n",
    "def combine_dois_gatilhos(df: pandas.DataFrame, days: int = 1) -> pandas.DataFrame:\n",
    "    \"\"\"\n",
    "    Para cada par de colunas '*_?gatilho':\n",
    "      1) calcula o rolling sum de 'days' dias apenas uma vez\n",
    "      2) soma as duas séries já roladas\n",
    "      3) guarda no dict new_cols\n",
    "    No fim, concatena new_cols ao df em um único passo, evitando fragmentação.\n",
    "    \"\"\"\n",
    "    # 1) identifica e calcula rolling\n",
    "    gatilho_cols = [\n",
    "        c for c in df.columns\n",
    "        if c.endswith('_?gatilho') or '_?persistence' in c\n",
    "    ]\n",
    "    print(f'Total de _?gatilhos: {len(gatilho_cols)}')\n",
    "    rolling_sums = df[gatilho_cols].rolling(window=days).sum()\n",
    "\n",
    "    # 2) monta todas as combinações\n",
    "    new_cols = {}\n",
    "    total = len(gatilho_cols) * (len(gatilho_cols) - 1) // 2\n",
    "    for col1, col2 in tqdm(itertools.combinations(gatilho_cols, 2),\n",
    "                           total=total,\n",
    "                           desc=\"Combinando gatilhos\"):\n",
    "        base1 = col1.replace('_?gatilho', '')\n",
    "        base2 = col2.replace('_?gatilho', '')\n",
    "        new_name = f\"{base1}_{base2}&2_?gatilho\"\n",
    "\n",
    "        combined = rolling_sums[col1] + rolling_sums[col2]\n",
    "        ic(new_name, combined.iloc[-1])\n",
    "        new_cols[new_name] = combined\n",
    "\n",
    "    # 3) concatena tudo de uma vez\n",
    "    new_df = pandas.DataFrame(new_cols, index=df.index)\n",
    "    df = pandas.concat([df, new_df], axis=1)\n",
    "\n",
    "    # 4) opcional: consolida blocos para prevenir fragmentação residual\n",
    "    df = df.copy()\n",
    "\n",
    "    return df\n",
    "'''\n",
    "\n",
    "def combine_dois_gatilhos(df, days = 1):\n",
    "    \"\"\"\n",
    "    Para cada par de colunas que terminam em '_?gatilho' OU contêm '_?persistence':\n",
    "        1) calcula rolling-sum dos últimos `days`;\n",
    "        2) converte para sinal (+1, 0, -1);\n",
    "        3) cria coluna combinada:\n",
    "               +1 se ambos +1,\n",
    "               -1 se ambos -1,\n",
    "                0 caso contrário.\n",
    "    Retorna o DataFrame original com as novas colunas anexadas.\n",
    "    \"\"\"\n",
    "    # ---------------- 1. Selecionar colunas de gatilho ----------------\n",
    "    gatilho_cols = [\n",
    "        c for c in df.columns\n",
    "        if c.endswith('_?gatilho') or '_?persistence' in c\n",
    "    ]\n",
    "\n",
    "    # ---------------- 2. Rolling + sinal para cada coluna -------------\n",
    "    roll_sign = {}\n",
    "    for col in gatilho_cols:\n",
    "        # soma dos últimos `days` valores\n",
    "        roll_sum = df[col].rolling(window=days, min_periods=days).sum()\n",
    "        # sinal: +1, 0, -1\n",
    "        roll_sign[col] = sign(roll_sum).astype('Int8')\n",
    "\n",
    "    # ---------------- 3. Combinar pares -------------------------------\n",
    "    new_cols = {}\n",
    "    total = len(gatilho_cols) * (len(gatilho_cols) - 1) // 2\n",
    "\n",
    "    for col1, col2 in tqdm(itertools.combinations(gatilho_cols, 2),\n",
    "                           total=total,\n",
    "                           desc=\"Combinando gatilhos\"):\n",
    "\n",
    "        base1 = col1.replace('_?gatilho', '')\n",
    "        base2 = col2.replace('_?gatilho', '')\n",
    "        new_name = f\"{base1}_{base2}&2_?gatilho\"\n",
    "\n",
    "        s1 = roll_sign[col1]\n",
    "        s2 = roll_sign[col2]\n",
    "\n",
    "        # +1 se ambos +1, -1 se ambos -1, senão 0\n",
    "        same_sign = (s1 == s2) & (s1 != 0)\n",
    "        combined = s1.where(same_sign, 0).astype('Int8')\n",
    "\n",
    "        new_cols[new_name] = combined\n",
    "\n",
    "    # ---------------- 4. Anexar ao DataFrame --------------------------\n",
    "    df[list(new_cols)] = pandas.DataFrame(new_cols, index=df.index)\n",
    "\n",
    "    return df\n",
    "\n",
    "def encontre_corr_media_indicadores_tecnicos(df: pandas.DataFrame) -> pandas.DataFrame:\n",
    "    \"\"\"\n",
    "    Para cada par (coluna *_?alta*, coluna *_?gatilho* ou *_?persistence*)\n",
    "    calcula:\n",
    "      · correlação de Pearson + p-valor\n",
    "      · média de *var_desloc* filtrada\n",
    "      · média de *var_desloc* quando o gatilho = 1  (Media_Desloc_1)\n",
    "      · média de *var_desloc* quando o gatilho = –1 (Media_Desloc_-1)\n",
    "    \"\"\"\n",
    "    cols_alta = [c for c in df.columns if c.endswith('_?alta')]\n",
    "\n",
    "    # agora coleta tanto *_?gatilho* quanto *_?persistence_kdays*\n",
    "    cols_gatilho = [\n",
    "        c for c in df.columns\n",
    "        if c.endswith('_?gatilho') or '_?persistence' in c\n",
    "    ]\n",
    "\n",
    "    resultados = []\n",
    "\n",
    "    for col_alta in tqdm(cols_alta, desc=\"Calculando Correlações\"):\n",
    "        serie_alta = df[col_alta]\n",
    "\n",
    "        # ---- coluna de deslocamento correspondente ----\n",
    "        col_desloc = col_alta.replace('_?alta', '_var_desloc')\n",
    "        serie_desloc = df[col_desloc] if col_desloc in df.columns else None\n",
    "\n",
    "        for col_gat in cols_gatilho:\n",
    "            serie_gat = df[col_gat]\n",
    "\n",
    "            indicadores = 2 if '&2' in col_gat else 1\n",
    "\n",
    "            # filtro básico pelo gatilho\n",
    "            mask = serie_gat != 0\n",
    "            mask &= serie_alta.notna() & serie_gat.notna()\n",
    "            mask &= isfinite(serie_alta) & isfinite(serie_gat)\n",
    "\n",
    "            if serie_desloc is not None:\n",
    "                mask &= serie_desloc.notna() & isfinite(serie_desloc)\n",
    "\n",
    "            qtd = int(mask.sum())\n",
    "            if qtd > 1:\n",
    "                x = serie_alta[mask]\n",
    "                y = serie_gat[mask]\n",
    "\n",
    "                corr, p_val = pearsonr(x, y)\n",
    "\n",
    "                # --------- médias de deslocamento ---------\n",
    "                if serie_desloc is not None:\n",
    "                    media_desloc_all = float(serie_desloc[mask].mean())\n",
    "\n",
    "                    mask_long  = mask & (serie_gat == 1)\n",
    "                    media_desloc_1 = (\n",
    "                        float(serie_desloc[mask_long].mean())\n",
    "                        if mask_long.any() else nan\n",
    "                    )\n",
    "\n",
    "                    mask_short = mask & (serie_gat == -1)\n",
    "                    media_desloc_minus1 = (\n",
    "                        float(serie_desloc[mask_short].mean())\n",
    "                        if mask_short.any() else nan\n",
    "                    )\n",
    "                else:\n",
    "                    media_desloc_all = media_desloc_1 = media_desloc_minus1 = nan\n",
    "\n",
    "                resultados.append({\n",
    "                    'Coluna_Alta': col_alta,\n",
    "                    'Coluna_Gatilho': col_gat,\n",
    "                    'Correlacao': corr,\n",
    "                    'Coincidência >0.05': p_val,\n",
    "                    'Quantidade_Linhas': qtd,\n",
    "                    'Indicadores': indicadores,\n",
    "                    'Media_Desloc': media_desloc_all,\n",
    "                    'Media_Desloc_1': media_desloc_1,\n",
    "                    'Media_Desloc_-1': media_desloc_minus1\n",
    "                })\n",
    "\n",
    "    return pandas.DataFrame(resultados)\n",
    "\n",
    "\n",
    "def calcular_medias(ticker, df, filtro, days_list):\n",
    "    \"\"\"\n",
    "    Calcula as médias, pencentagem de montagens ganhadoras das colunas em colunas_necessarias   \n",
    "    Parâmetros:\n",
    "    ticker - Trago lá de extração yfinance o nome do ticker\n",
    "    df - É o df que já passou pelo filtro na função que enviou esses argumentos\n",
    "    filtro - são os filtros usados pelo df anterior para adicionar essa informação ao df\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    # Essa linha é igual a da função adicione_variacoes_dataframe do bloco técnico. Mas elas criam essas colunas em dfs diferentes\n",
    "    colunas_necessarias = [ f'Var_{days}d' for days in days_list]\n",
    "    \n",
    "    # Calculando médias, desvios padrões e porcentagem de valores acima de 0\n",
    "    medias = df[colunas_necessarias].mean()\n",
    "    desvios = df[colunas_necessarias].std()\n",
    "    quant_acima_de_0 = df[colunas_necessarias].gt(0).sum()\n",
    "    acima_de_0 = quant_acima_de_0 / df[colunas_necessarias].count() * 100\n",
    "\n",
    "    #if len(df) >= 30: # Registrar somente observações mais relevantes\n",
    "\n",
    "    # Inicializando o dicionário para o DataFrame de apuração\n",
    "    apuracao_dict = {\n",
    "        'Filtros': [filtro],\n",
    "        'Linhas': [len(df)],\n",
    "        'Indicadores técnicos': [len(filtro)],\n",
    "    }\n",
    "    \n",
    "    # Adicionando médias e percentuais dinamicamente\n",
    "    for days in days_list:\n",
    "        apuracao_dict[f'média {days}d'] = [medias[f'Var_{days}d']]\n",
    "    for days in days_list:\n",
    "        apuracao_dict[f'%alta_{days}d'] = [acima_de_0[f'Var_{days}d']]\n",
    "\n",
    "    # Criando o DataFrame de apuração\n",
    "    apuracao = pandas.DataFrame(apuracao_dict)\n",
    "\n",
    "    return apuracao\n",
    "\n",
    "\n",
    "def liste_combinacoes_tecnicas(df, x=None):\n",
    "    \"\"\"\n",
    "    Pega um df com todos as montagens, encontra todas que as colunas que participaram da análise técnica: \"_?value\", \n",
    "    Depois, dependendo do valor de x, encontra todas combinações únicas entre x colunas ou entre todas as colunas, se x for None.\n",
    "    Dúvidas, print \"combinações\"\n",
    "    \n",
    "    Parâmetros:\n",
    "    - df: DataFrame com os dados.\n",
    "    - x: Número opcional de colunas para combinar. Se None, combina todas as colunas.\n",
    "    \n",
    "    Retorna: Todas as colunas que participaram das combinações, todas as combinações\n",
    "    Todos os valore únicos. Serão usados para levantar o range de coluna valor na função \n",
    "    apure_resultado_segmentado_combinacao_tecnica\n",
    "    \n",
    "    \"\"\"\n",
    "    # Selecionar colunas que terminam com \"_?value\"\n",
    "    colunas_value = [col for col in df.columns if col.endswith('_?value')]\n",
    "\n",
    "    # Registrar valores únicos para cada coluna \"_?value\"\n",
    "    valores_unicos_colunas = {coluna: df[coluna].unique() for coluna in colunas_value}\n",
    "        \n",
    "    # Dicionário para armazenar as combinações de colunas e seus valores únicos correspondentes\n",
    "    combinacoes_dict = {}\n",
    "    \n",
    "    # Se x for especificado e for menor que o número total de colunas, gerar combinações de colunas\n",
    "    if x is not None and x <= len(colunas_value):\n",
    "        combinacao_colunas = list(itertools.combinations(colunas_value, x))\n",
    "        for cols in combinacao_colunas:\n",
    "            # Gerar todas as combinações possíveis dos valores nas colunas selecionadas para cada conjunto de combinação de colunas\n",
    "            combinacoes_valores = list(itertools.product(*(valores_unicos_colunas[col] for col in cols)))\n",
    "            combinacoes_dict[cols] = combinacoes_valores\n",
    "    else:\n",
    "        # Para combinar todas as colunas, usar diretamente o itertools.product\n",
    "        combinacoes_valores = list(itertools.product(*(valores_unicos_colunas[col] for col in colunas_value)))\n",
    "        combinacoes_dict[tuple(colunas_value)] = combinacoes_valores\n",
    "\n",
    "    return combinacoes_dict, colunas_value, valores_unicos_colunas\n",
    "  \n",
    "\n",
    "def apure_resultado_segmentado_combinacao_tecnica(ticker, df, combinacoes_dict, resultados_temp, colunas_value, valores_unicos_colunas):\n",
    "    \"\"\"\n",
    "    Fitra o df para cada combinação na lista de combinações técnicas.\n",
    "    Depois, com aquele filtro, levanta quanto deu as médias e os %alta, chamando a função calcular_medias\n",
    "    O resultado será um df com as médias e desvios para 10d, 20d, 30d e 60d por filtro\n",
    "                                \n",
    "    \"\"\" \n",
    "    \n",
    "    # Precisa zerar para não acumular os resultados do ticker anterior\n",
    "    resultados_temp = []\n",
    "\n",
    "    # Iterar sobre cada combinação de colunas no dicionário de combinações    \n",
    "    for colunas_combinacao, combinacoes_valores in combinacoes_dict.items():\n",
    "        # Iterar sobre cada combinação de valores para as colunas atuais\n",
    "        for valores_combinacao in combinacoes_valores:\n",
    "            filtro = dict(zip(colunas_combinacao, valores_combinacao))\n",
    "            df_filtrado = df.copy()\n",
    "\n",
    "            # Aplicar filtros\n",
    "            for col, val in filtro.items():\n",
    "                df_filtrado = df_filtrado[df_filtrado[col] == val]\n",
    "\n",
    "            # Supondo que calcular_medias é uma função que você definirá para calcular as médias e desvios\n",
    "            resultados_temp.append(calcular_medias(ticker, df_filtrado, filtro, days_list))            \n",
    "\n",
    "    # Concatenar todos os resultados temporários em um único DataFrame, se resultados_temp não estiver vazio\n",
    "    apuracao = pandas.concat(resultados_temp, ignore_index=True) if resultados_temp else pandas.DataFrame()    \n",
    "    \n",
    "    # Criar uma lista para armazenar todos os valores, sem repetições\n",
    "    all_values_col = list(set([value for values in valores_unicos_colunas.values() for value in values]))\n",
    "       \n",
    "    # Apurando a contribuição que cada item no filtro\n",
    "    for coluna in colunas_value:\n",
    "        \n",
    "        for values in all_values_col:\n",
    "                    \n",
    "            df_filtrado = df.copy()\n",
    "            df_filtrado = df_filtrado[df_filtrado[coluna] == values]\n",
    "            \n",
    "            # Concatenar todos os resultados temporários em um único DataFrame\n",
    "            resultados_temp.append(calcular_medias(ticker, df_filtrado, {coluna:values}, days_list))            \n",
    "            apuracao = pandas.concat(resultados_temp, ignore_index=True)    \n",
    "    \n",
    "    return apuracao\n",
    "       \n",
    "        \n",
    "def calcule_risco_retorno_combinacoes_tecnicas(ticker, apuracao):\n",
    "    \"\"\"\n",
    "    Ao arquivo de apuração dos resultados combinados, essa função vai acrescentar colunas importantes:\n",
    "    \n",
    "    Soma das médias\tSoma dos desvios\tdiferença das médias\tsharp\tranking sharp\tvariação retorno\tvariação desvio\tretorno-2risco\tranking retorno-2risco\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Ordenando o DataFrame pela melhor média para apuração de 20 dias de montagens\n",
    "    apuracao = apuracao.sort_values(by=\"média 20d\", ascending=False)\n",
    "    # Adicionando uma coluna de \"ranking\" técnico\n",
    "    apuracao[\"ranking média\"] = range(1, len(apuracao) + 1)\n",
    "    \n",
    "    # Ordenando o DataFrame pela porcentagem de alta na apuração de 20 dias de montagens\n",
    "    apuracao = apuracao.sort_values(by=\"%alta_20d\", ascending=False)\n",
    "    # Adicionando uma coluna de \"ranking\" técnico\n",
    "    apuracao[\"ranking %alta\"] = range(1, len(apuracao) + 1)\n",
    "    \n",
    "    # Adicionando o ranking por indicador técnico (filtros com um único indicador)\n",
    "    apuracao['ranking Ind. Técnicos'] = None\n",
    "    # Identificar as linhas que atendem à condição de ter um único indicador técnico\n",
    "    condicao = (apuracao['Indicadores técnicos'] == 1)\n",
    "    # Aplicar o ranking apenas nas linhas que satisfazem a condição\n",
    "    apuracao.loc[condicao, 'ranking Ind. Técnicos'] = range(1, condicao.sum() + 1)\n",
    "            \n",
    "    # CHECK - Exportar resultados para um arquivo Excel--------------------------------------\n",
    "    # apuracao.to_excel(f'RCOMB-{ticker}- {nome_arquivo}.xlsx', index=False)\n",
    "    \n",
    "    return apuracao\n",
    "\n",
    "def buscar_e_adicionar_colunas(df, apuracao):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Inicializar as novas colunas com valores NaN\n",
    "    df['%alta_20d'] = float('nan')\n",
    "    df['ranking %alta'] = float('nan')\n",
    "    \n",
    "    # Iterar sobre cada linha do DataFrame de fechamento\n",
    "    for idx, row in df.iterrows():\n",
    "        \n",
    "        chave = row['chave_configuracoes_tec']\n",
    "        \n",
    "        # Procurar a linha correspondente no DataFrame de análise\n",
    "        linha_analise = apuracao[apuracao['Filtros'] == chave]\n",
    "        \n",
    "        if not linha_analise.empty:\n",
    "            df.at[idx, '%alta_20d'] = linha_analise['%alta_20d'].values[0]\n",
    "            df.at[idx, 'ranking %alta'] = linha_analise['ranking %alta'].values[0]\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea45063",
   "metadata": {},
   "source": [
    "## Principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd819d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Tickers:   3%|▎         | 9/277 [00:06<02:30,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao calcular ALPA3.SA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Tickers:  22%|██▏       | 60/277 [00:39<02:10,  1.66it/s]\n",
      "1 Failed download:\n",
      "['CLSA3.SA']: YFPricesMissingError('possibly delisted; no price data found  (1d 2020-06-11 19:58:58.914194 -> 2025-06-11) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "Processando Tickers:  22%|██▏       | 61/277 [00:40<02:19,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao calcular CLSA3.SA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Tickers:  23%|██▎       | 65/277 [00:43<02:40,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao calcular COCE5.SA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Tickers: 100%|██████████| 277/277 [03:07<00:00,  1.48it/s]\n"
     ]
    }
   ],
   "source": [
    "#1. ANÁLISE TÉCNICA\n",
    "\n",
    "#1.1 - Escaneando ticker e atribuindo leitura técnica \n",
    "ticker_list = ler_todos_tickers()\n",
    "\n",
    "# Exportações de df técnico. Máximo 2 tickers--------------------------\n",
    "# ticker_list = {'ticker':['mglu3', 'simh3', 'brav3','caml3']}\n",
    "# ticker_list = {'ticker':['mrve3', 'BRAV3','PRIO3','AZUL4'] }\n",
    "# ---------------------------------------------------------------------\n",
    "# check que linhas do código rodar.\n",
    "test_indicadores = True                      \n",
    "todas_montagens_tecnicas = screener(ticker_list['ticker'])\n",
    "\n",
    "# Check -----\n",
    "todas_montagens_tecnicas[1].to_excel(f'aquela_testada.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c859d74-922f-447b-a290-5770835a6c03",
   "metadata": {},
   "source": [
    "### Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5711f7fb-7c10-4138-8fa5-2e66af162b7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Combinando gatilhos: 100%|██████████| 861/861 [00:02<00:00, 287.99it/s]\n",
      "Calculando Correlações: 100%|██████████| 5/5 [00:55<00:00, 11.05s/it]\n"
     ]
    }
   ],
   "source": [
    "if test_indicadores:\n",
    "    # Combinar 2 gatilhos\n",
    "    todas_montagens_tecnicas = combine_dois_gatilhos(todas_montagens_tecnicas[1])\n",
    "    relatorio_correlacoes = encontre_corr_media_indicadores_tecnicos(todas_montagens_tecnicas)                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a9f911-1321-4d16-9a34-d9f3cd8de455",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52e88853-4e70-4a89-92a3-b7cf78c92792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relatorio_correlacoes exportado\n"
     ]
    }
   ],
   "source": [
    "if test_indicadores:\n",
    "    relatorio_correlacoes.to_excel(f'relatorio_correlacoes.xlsx')\n",
    "    print('relatorio_correlacoes exportado')\n",
    "else:\n",
    "    todas_montagens_tecnicas.to_excel(f'relatorio_correlacoes.xlsx')\n",
    "    print(nome_arquivo,' exportado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "186b6ad3-b0ad-4e47-9c69-4ab3d8f256a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3. Outras Formas de Backtesting Conhecidas\\nHá diversas metodologias para aprimorar seus backtests e capturar com maior profundidade a eficiência dos indicadores. Abaixo estão algumas delas:\\n\\na. Monte Carlo Simulations\\nAo invés de simplesmente testar estratégias com dados históricos fixos, você pode aplicar Simulações de Monte Carlo para gerar múltiplos cenários futuros aleatórios baseados nas características do mercado (volatilidade, retorno esperado, etc). Isso ajuda a capturar uma variedade de resultados possíveis e a avaliar a robustez das suas estratégias.\\nb. Walk-Forward Testing\\nEsse método envolve recalibrar os parâmetros do modelo em uma janela de tempo específica e, em seguida, testar a estratégia na próxima janela (fora do conjunto de treinamento). Essa abordagem evita o overfitting e oferece uma melhor avaliação da performance real da estratégia em condições de mercado variáveis.\\nc. Análise de Sensibilidade\\nA análise de sensibilidade consiste em variar sistematicamente os parâmetros dos indicadores (por exemplo, diferentes períodos para médias móveis, largura das bandas de Bollinger, etc.) para identificar quais valores produzem melhores resultados e onde a estratégia é mais sensível a mudanças.\\nd. Estratégias Multi-Fatoriais\\nIndicadores técnicos frequentemente têm mais valor quando usados em combinação com outros fatores, como fatores fundamentais (P/L, crescimento de receita, etc.) ou fatores macroeconômicos. Incorporar um modelo multi-fatorial ou até utilizar técnicas como Análise de Componentes Principais (PCA) pode ajudar a identificar interações ocultas entre os fatores.\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"3. Outras Formas de Backtesting Conhecidas\n",
    "Há diversas metodologias para aprimorar seus backtests e capturar com maior profundidade a eficiência dos indicadores. Abaixo estão algumas delas:\n",
    "\n",
    "a. Monte Carlo Simulations\n",
    "Ao invés de simplesmente testar estratégias com dados históricos fixos, você pode aplicar Simulações de Monte Carlo para gerar múltiplos cenários futuros aleatórios baseados nas características do mercado (volatilidade, retorno esperado, etc). Isso ajuda a capturar uma variedade de resultados possíveis e a avaliar a robustez das suas estratégias.\n",
    "b. Walk-Forward Testing\n",
    "Esse método envolve recalibrar os parâmetros do modelo em uma janela de tempo específica e, em seguida, testar a estratégia na próxima janela (fora do conjunto de treinamento). Essa abordagem evita o overfitting e oferece uma melhor avaliação da performance real da estratégia em condições de mercado variáveis.\n",
    "c. Análise de Sensibilidade\n",
    "A análise de sensibilidade consiste em variar sistematicamente os parâmetros dos indicadores (por exemplo, diferentes períodos para médias móveis, largura das bandas de Bollinger, etc.) para identificar quais valores produzem melhores resultados e onde a estratégia é mais sensível a mudanças.\n",
    "d. Estratégias Multi-Fatoriais\n",
    "Indicadores técnicos frequentemente têm mais valor quando usados em combinação com outros fatores, como fatores fundamentais (P/L, crescimento de receita, etc.) ou fatores macroeconômicos. Incorporar um modelo multi-fatorial ou até utilizar técnicas como Análise de Componentes Principais (PCA) pode ajudar a identificar interações ocultas entre os fatores.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
